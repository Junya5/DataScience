# 颈动脉分割

## 上周工作

### normalization
- normalization的cmake在linux上可执行了，主要修改了normalization的读入函数readITK（从dicom series改成了file格式），其他保持不变，由于颈动脉数据是HU值加上1024后的unsigned short格式，所以把图像转成了signed short格式，然后减去了1024恢复成HU值，所有图像resample到一样spacing和大小，以challenge000作为target，其他图像作为source作为normalization的输入。
- 下表是血管处的pixelValue。<br>

sample | before normalization | after normalization
---|---|---
challenge001| 340-370| 340左右
challenge002| 480-500| 500-560
challenge100| 270-300| 50-70
challenge102| 400-455| 140-180

- 经过normalization后血管的pixelValue变得更加不集中，分布得更散了。因此网络训练中的数据并未采用经过normalization的。

### dataGenerator
- 目的：把测试集的数据加进来后，数据量不能一次性载入内存，为了实现每个epoch不放回的载入部分数据
- 预处理：原始图像减去1024后resample后，统一除以3071（4095-1024），在startIndex:(150, 150, 245)--endIndex: (378, 378, 697))这个范围内以overlap(30, 30, 20)切割(96, 96, 128)大小的patches
- 实现：
1. patches保存成npy格式，并且把patches的名字写入txt中
2. 读txt把patches的名字变成list,每个epoch开始时把list打乱，然后按顺序从前往后取N个名字，依照名字读入npy文件，作为一个batch

### 网络训练
- 输入：上述dataGenerator预处理后的数据
- 结构：深度为4的UNET，loss=binary_crossentropy
- 结果：从开始到8个epoch时学习曲线基本停滞，采用学习权重来预测，结果为全0
- 分析：由于foreground和background的严重不均衡导致，label中负样本和正样本的比值约为1400

## 正在努力中

1. weighted_BCE

```

   From: targets * -log(sigmoid(logits)) + (1 - targets) * -log(1 - sigmoid(logits))
   To:   targets * -log(sigmoid(logits)) * pos_weight + (1 - targets) * -log(1 - sigmoid(logits))

```
采用了pos_weight = 1000, 如果采用此loss function,网络最后activation=None，因为为了稳定不溢出，loss function中计算了sigmoid

2. focal loss (https://arxiv.org/abs/1708.02002)

```
FL(pt) = −(1 − pt)^γlog(pt) 
pt = p if y==1 else 1-p
```
如果采用此loss function,网络最后activation=None

3. initilization？ ？<br>
网络最后一层采用bias ≈ -1.996

## 下一步计划

1. 以label=1的pixel为中心，切割patch加入训练集以提高正样本比例
- 但是，即使取得正样本比例最高的区域——刚好囊括了血管分叉，正样本比例也很低，估计效果有限

2. normalization的threshold、sigma和iteration调整
- 不着急，先解决不均衡问题

3. signed distance map
- 离散化？如果离散化，看成多分类问题？